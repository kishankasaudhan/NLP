{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kishankasaudhan/NLP/blob/main/gensim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eDYS0SJekhe",
        "outputId": "710b1c07-7f54-42c9-dfe0-7ce145e6df67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "t1MIG1QCes8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEZQotPYf1he",
        "outputId": "41643ed0-5eb7-4adb-f52d-ea5924df5372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=[\n",
        "    \"I am learning natural language processing\",\n",
        "    \"Natural language processing is part of machine learning\",\n",
        "    \"I am also learning machine learning\",\n",
        "    \"I want to learn deep learning\",\n",
        "    \"Deep learning uses neural networks\",\n",
        "    \"Neural networks are powerful\"\n",
        "]"
      ],
      "metadata": {
        "id": "-xHNsnRAey2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences=[word_tokenize(s.lower()) for s in sentences]"
      ],
      "metadata": {
        "id": "vbZB_sZAfjev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvVecIctfsto",
        "outputId": "5a997a22-3b5f-4e2b-87f8-bafe4250e992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['i', 'am', 'learning', 'natural', 'language', 'processing'], ['natural', 'language', 'processing', 'is', 'part', 'of', 'machine', 'learning'], ['i', 'am', 'also', 'learning', 'machine', 'learning'], ['i', 'want', 'to', 'learn', 'deep', 'learning'], ['deep', 'learning', 'uses', 'neural', 'networks'], ['neural', 'networks', 'are', 'powerful']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Word2Vec(\n",
        "    sentences=tokenized_sentences,\n",
        "    vector_size=100, #Embedding_dimension- dimension of word vectors\n",
        "    window=3,        #context-window size - max distance b/w target and context words\n",
        "    min_count=1      #keep all words- igonre worrds appearing less than this number\n",
        ")"
      ],
      "metadata": {
        "id": "Y0zY3Zocf62Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.wv.similarity(\"language\",\"natural\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvA1gUyWgvJO",
        "outputId": "10f29ae7-5c6f-4682-9f4d-11aa3cd27dc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.1444947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.wv.most_similar(\"deep\",topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZbdhE14g2rU",
        "outputId": "1c0e6bf2-03f2-4ff7-b0e3-4eb8b10acbf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('learn', 0.2529045641422272), ('networks', 0.17009972035884857), ('uses', 0.15013892948627472), ('machine', 0.13887980580329895), ('also', 0.10851401835680008)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Internally\n",
        "# During training:\n",
        "# model slides window across text\n",
        "# learn wieghts via neural networks\n",
        "# produces embedding matrix\n",
        "\n",
        "# Word2Vec is:\n",
        "# a shadow neural network with one hidden layer only\n",
        "\n",
        "# Limitation of Word2Vec:\n",
        "# Static embeddings( Same vector for every context)\n"
      ],
      "metadata": {
        "id": "ZRRVf-KeiPvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use pretrained models\n",
        "# 2 popular pretrained models\n",
        "# 1. Google news Word2Vec (300 dimension)\n",
        "# 2. GloVe (Stanford)"
      ],
      "metadata": {
        "id": "hUP805CGiY8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "print(\"Loading pretrained models:\")\n",
        "model= api.load(\"glove-wiki-gigaword-100\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxV-mJjzj5R-",
        "outputId": "3720ca61-796c-4754-ab1e-135cfa9cfd4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pretrained models:\n",
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.similarity(\"artificial\",\"intelligence\"))\n",
        "print(model.most_similar(\"happy\",topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rndn6pl8kXjn",
        "outputId": "8861cf3b-11be-41d0-a86d-3fafdc9b6796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21335427\n",
            "[(\"'m\", 0.8413287997245789), ('feel', 0.8132575750350952), (\"'re\", 0.8048083186149597), ('i', 0.7938276529312134), (\"'ll\", 0.7916273474693298)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "print(\"Loading pretrained models:\")\n",
        "model= api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6wXYL7-lLsE",
        "outputId": "7b1b373b-b034-4a78-d242-3b84f74b70f0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pretrained models:\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.similarity(\"artificial\",\"intelligence\"))\n",
        "print(model.most_similar(\"happy\",topn=15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pku4iUVLlZXM",
        "outputId": "bc1e177c-ba5d-4e1b-cf57-aaabe286a2c5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0064100265\n",
            "[('glad', 0.7408890724182129), ('pleased', 0.6632170677185059), ('ecstatic', 0.6626912355422974), ('overjoyed', 0.6599286794662476), ('thrilled', 0.6514049172401428), ('satisfied', 0.6437949538230896), ('proud', 0.636042058467865), ('delighted', 0.627237856388092), ('disappointed', 0.6269949674606323), ('excited', 0.6247665286064148), ('happier', 0.6244627237319946), ('Said_Hirschbeck', 0.6234508752822876), ('elated', 0.6196017861366272), ('thankful', 0.6178935766220093), ('unhappy', 0.6128038167953491)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing Dimensionality Reduction\n",
        "# Reducing number of features while  rpeserving the important information\n",
        "# -We have to reduce dimension from 100D to 2D\n",
        "# -Because we cannot visualize 100D\n",
        "# This let us vusally see:\n",
        "# Similar words cluster together\n",
        "# Opposite words separate\n",
        "# Semantic relationships"
      ],
      "metadata": {
        "id": "mUop6KG0nRGD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#We can reduce Dimensions by using:\n",
        "#1. PCA- Linear Reduction\n",
        "#- PCA finds direction where data varies most\n",
        "#-Directions= Principal Components\n",
        "\n",
        "Suppose students:\n",
        "-height and weight are correlated\n",
        "-instead of 2 features- PCA create 1 new feature representing both\n",
        "\n",
        "Steps of PCA:\n",
        "1.Standardize data\n",
        "2.Compute covariance matrix\n",
        "3.Find eigenvectors\n",
        "4.Select top components\n",
        "5.Project the data\n",
        "\n",
        "\n",
        "#2. t-SNE- Non Linear\n",
        "t-distributed Stochastic Neighbour Embedding\n",
        "Preseves local structure (neighbors)\n",
        "Points close in high dim-> close in low dim\n",
        "\n",
        "Steps of t-SNE\n",
        "1. It converts distance -> probabilities\n",
        "2. Then tries to match them in low dimension\n",
        "3. Then uses KL divergence\n",
        "\n",
        "\n",
        "#3. UMAP-\n",
        "Uniform Manifold Approximation and Projection\n",
        "Modern Alternnative of t-SNE\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "sK_oIfiWQLwp",
        "outputId": "f67b2468-65c6-489c-ff85-ee41da3bdd9c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#We can reduce Dimensions by using:\\n#1. PCA- Linear Reduction\\n#- PCA finds direction where data varies most\\n#-Directions= Principal Components\\n\\nSuppose students:\\n-height and weight are correlated\\n-instead of 2 features- PCA create 1 new feature representing both\\n\\nSteps of PCA:\\n1.Standardize data\\n2.Compute covariance matrix\\n3.Find eigenvectors\\n4.Select top components\\n5.Project the data\\n\\n\\n#2. t-SNE- Non Linear\\nt-distributed Stochastic Neighbour Embedding\\nPreseves local structure (neighbors)\\nPoints close in high dim-> close in low dim\\n\\nSteps of t-SNE\\n1. It converts distance -> probabilities\\n2. Then tries to match them in low dimension\\n3. Then uses KL divergence\\n\\n\\n#3. UMAP-\\nUniform Manifold Approximation and Projection\\nModern Alternnative of t-SNE\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "GstI-_XBT8QT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "print(\"Model print successfully\")"
      ],
      "metadata": {
        "id": "ppS7U8AJUWxA",
        "outputId": "823ad25d-1087-46e1-d16f-814201f80666",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model print successfully\n"
          ]
        }
      ]
    }
  ]
}