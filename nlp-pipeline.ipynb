{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr3a7YQzyk7s4GyUoM5puW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kishankasaudhan/NLP/blob/main/nlp-pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jiWkKMbURSfd"
      },
      "outputs": [],
      "source": [
        "#Text processing pipeline\n",
        "#text -> Cleaning -> Tokenization -> Stopwords Removal -> Stemming/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"i am learning Python programming and Python is fast\"\n",
        "print(\"Original text : \", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkDmYg79Sdfm",
        "outputId": "c01200e4-4054-496d-d318-b187ef5541ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text :  i am learning Python programming and Python is fast\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ste-1: Convert to lowercase\n",
        "text = text.lower()\n",
        "#Python != pythonn\n",
        "print(\"Lowercase: \",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyLnhsuWSqyV",
        "outputId": "c2c5c70b-8ac6-4c42-de53-cc5dc002a711"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercase:  i am learning python programming and python is fast\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step-2: Remove Punctuation - !@#$%^&*():,.\n",
        "# re - regular expressions\n",
        "import re\n",
        "text = re.sub(r'[^\\w\\s]','',text)\n",
        "#r means raw string , it automatically makes the single / into // so no confusion\n",
        "#remove everything except letters and spaces\n",
        "print(\"Punctuation removed: \",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7sSUkDiTDwu",
        "outputId": "d04b70f2-9c61-425d-9c4b-b27d22d6cf0a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Punctuation removed:  i am learning python programming and python is fast\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step-3: Tokenization\n",
        "tokens = text.split()\n",
        "print(\"Tokens: \",tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2zNwXesWIUj",
        "outputId": "4cac9e14-ba07-47da-b2d9-b4b9aabd5948"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens:  ['i', 'am', 'learning', 'python', 'programming', 'and', 'python', 'is', 'fast']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step-4: Romove Stopwords - is, am , are , the, a, an\n",
        "stopwords = [\"a\",\"an\",\"is\",\"i\",\"the\",\"and\"]\n",
        "filtered_tokens = []\n",
        "for word in tokens:\n",
        "  if word not in stopwords:\n",
        "    filtered_tokens.append(word)\n",
        "print(\"After removing stopwords: \",filtered_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7rgbhRgWnn6",
        "outputId": "2070a1fe-c340-477e-b239-c4f6afe87968"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After removing stopwords:  ['am', 'learning', 'python', 'programming', 'python', 'fast']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stem(word):\n",
        "  if word.endswith(\"ing\"):\n",
        "    return word[:-3]\n",
        "  return word\n",
        "stemmed_words = []\n",
        "for word in filtered_tokens:\n",
        "  stemmed_words.append(stem(word))\n",
        "print(\"After stemming: \",stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvEqhs4ZXyVh",
        "outputId": "67be7b17-58b2-4dfe-83aa-5369013f6c1e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After stemming:  ['am', 'learn', 'python', 'programm', 'python', 'fast']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLP PHASE-2: Word to Vector"
      ],
      "metadata": {
        "id": "mWWGORCXYoJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Why Vectors?\n",
        "# --> beacuse\n",
        "\n",
        "\n",
        "\n",
        "#Will convert text -> count\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "luAkwkQQY00b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"i am learning python and python\",\n",
        "    \"we are happy today\",\n",
        "    \"i am sad today\"\n",
        "]"
      ],
      "metadata": {
        "id": "BvMBe40XZSya"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()  #Create object\n",
        "X = vectorizer.fit_transform(sentences)\n",
        "#learns vocabulary\n",
        "#convert sentences to numbers"
      ],
      "metadata": {
        "id": "rM2hiD_ZZ48Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocabulary :\",vectorizer.get_feature_names_out())\n",
        "#1. all unique words\n",
        "#2. sorted in aplphabetical order\n",
        "#3. remove single letters like a,i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgkpNP4Pabp-",
        "outputId": "b777824d-2dbc-49b3-f45f-39b434b2e2a7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary : ['am' 'and' 'are' 'happy' 'learning' 'python' 'sad' 'today' 'we']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vectors: \")\n",
        "print(X.toarray())\n",
        "#Each row is a sentence\n",
        "#Each column is a word\n",
        "#Each value is a count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S9eDEFDcBLQ",
        "outputId": "c4fbb228-1e4f-4b9a-ee07-c528568ef90a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectors: \n",
            "[[1 1 0 0 1 2 0 0 0]\n",
            " [0 0 1 1 0 0 0 1 1]\n",
            " [1 0 0 0 0 0 1 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF = Term Frequency - Inverse Document"
      ],
      "metadata": {
        "id": "n4z_HhaEdH8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#why tf-idf?\n",
        "#because count is not enough\n",
        "#"
      ],
      "metadata": {
        "id": "Muo8WnGUdRz7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "tyXmOASmdoCT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=[\n",
        "    \"i am learning python and python\",\n",
        "    \"we are happy today\",\n",
        "    \"i am sad today\"\n",
        "]"
      ],
      "metadata": {
        "id": "O8p5pvNZdZ8t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(sentences)\n",
        "#build vocabulary\n",
        "#calculate TF\n",
        "# calculate idf - impact of each word\n",
        "#multiples - tf x idf\n",
        "#produces matrix"
      ],
      "metadata": {
        "id": "YLCbWUMpdz_Z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocabulary: \",vectorizer.get_feature_names_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJbO-xqEeRhC",
        "outputId": "45bc3420-4d02-4ea7-f726-cd8ae3619488"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:  <bound method CountVectorizer.get_feature_names_out of TfidfVectorizer()>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TF-IDF Matrix :\")\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD5VpO8Gegz8",
        "outputId": "88f00522-8a71-4171-d765-0d4afdf0665a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Matrix :\n",
            "[[0.29651988 0.38988801 0.         0.         0.38988801 0.77977602\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.         0.52863461 0.52863461 0.         0.\n",
            "  0.         0.40204024 0.52863461]\n",
            " [0.51785612 0.         0.         0.         0.         0.\n",
            "  0.68091856 0.51785612 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Count + Impact of each word\n",
        "#TF-IDF rewards are important words and penalizes common words"
      ],
      "metadata": {
        "id": "WWoPjFitfDge"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TF = count(words) / total_words\n",
        "#IDf = log(total_docs / documents_containing_words)"
      ],
      "metadata": {
        "id": "C8leu20OfOzd"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}